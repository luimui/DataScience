{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e330f2c4-c934-49ef-ab7c-f5e66c0b7703",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6684fe-6203-40b5-af63-ac9f8142d666",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd35b79-fd7f-444b-9c5b-11df76f5cb8a",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b319e527-5d9e-4c40-9719-8c8ffb385b67",
   "metadata": {},
   "source": [
    "#### Prediction possibilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54365c58-22cd-4611-a889-5828025cc047",
   "metadata": {},
   "source": [
    "For a binary classification problem, what are the four prediction possibilities? List their names and briefly explain what they represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5bf42f-227e-47af-84fc-71aef29d9357",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbbf349c-1e09-4694-88bb-ff388a87238b",
   "metadata": {},
   "source": [
    "#### Define the accuracy measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae14da-2ccc-47f9-947c-c3a911bebbc0",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67d7f206-adb2-4ff6-8d2d-17ecee906c1c",
   "metadata": {},
   "source": [
    "#### Define precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c190a648-73ae-4329-8728-81b57fff48d2",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d9fac6b-9640-49b5-b230-02857eeafc76",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Properties of precision and recall\n",
    "What can a classifier predicting the class `0` or `1` do to\n",
    "\n",
    "1) always get a *precision* of `1`\n",
    "1) always get a *recall* of `1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a046f87-c0c2-459a-a45a-75aa35e4c0c4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "placeholder"
    ]
   },
   "source": [
    "#### Application of precision and recall\n",
    "In what applications is precision more important than recall, and in which applications is recall more important than precision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0d0334-4bc4-4b06-bbb6-80f45e45daf9",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4dcf73ce-5cae-4b48-8b0d-fa55d9c1cb62",
   "metadata": {},
   "source": [
    "#### Combine precision and recall\n",
    "* What is a measure that combines precision and recall? \n",
    "* Define it.\n",
    "* Why do we use the harmonic rather than the arithmetic mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53294832-b6dc-4d74-b51b-178874a24f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "148af174-9333-40f9-a4ac-03680e83f1f1",
   "metadata": {},
   "source": [
    "#### Default values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8f8a1d-ce35-4c02-95fc-a1ea6f61a443",
   "metadata": {},
   "source": [
    "Consider the following, label set:\n",
    "\n",
    "* `y`: roughly the same amount of cases (`1`) and controls (`0`)\n",
    "\n",
    "Now, calculate the *accuracy*, *precision*, *recall*, and *ROC AUC*.\n",
    "\n",
    "1) For a classifier that returns random labels. What do you observe?\n",
    "2) For a classifier that always returns `1`. What do you observe?\n",
    "\n",
    "**Hints:**\n",
    "* You can simulate these classifiers without input data, i.e., by generating their predictions manually.\n",
    "* You can use `numpy` and `scikit-learn` to show these cases instead of answering theoretically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "98fea460-626b-4631-b830-f0c55e8cb081",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, classification_report\n",
    "\n",
    "np.random.seed(42)\n",
    "n = 1000\n",
    "\n",
    "# labels 1 (random)\n",
    "y = np.random.choice([0,1], p=(0.5, 0.5), size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d405ffad-4e56-4773-a528-ae15c6d867d5",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe513ecf-fa75-4ff4-a06d-f3f2491a8c96",
   "metadata": {},
   "source": [
    "#### Imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f255c78-dd8d-4e98-892c-ee644059387a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Consider the following, label set:\n",
    "\n",
    "* `y_imbalanced`:  only a small set of cases (`1`) compated to controls (`0`)\n",
    "\n",
    "Now, calculate the *accuracy*, *precision*, *recall*, and *ROC AUC*.\n",
    "\n",
    "1) For a classifier that returns random labels. What do you observe?\n",
    "2) For a classifier that always predicts the majority class (`0`). What do you observe and why could this be an issue in practice (particularly if we only consider `accuracy`)?\n",
    "5) Which class label does `scikit-learn` consider to be a \"case\", i.e., the class of interest?\n",
    "\n",
    "**Hints:**\n",
    "* You can simulate these classifiers without input data, i.e., by generating their predictions manually.\n",
    "* You can use `numpy` and `scikit-learn` to show these cases instead of answering theoretically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8205fab8-46f7-49e2-9ddc-3ea1ad03ee37",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, classification_report\n",
    "\n",
    "np.random.seed(42)\n",
    "n = 1000\n",
    "\n",
    "# labels 2 (imbalanced, i.e., small sets of `cases` (label=1))\n",
    "y_imbalance = np.random.choice([0,1], p=(0.9, 0.1), size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f832b4-6767-472d-b197-ca562bea3eb1",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22ea844b-0e7d-43d1-822e-eb82b4247ef9",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080c9ee3-793f-4457-83e4-2209e8d5b4e5",
   "metadata": {},
   "source": [
    "#### MAE vs MSE\n",
    "\n",
    "1. Write down the formulas for MAE and MSE.\n",
    "2. When would you use MAE and when would you use MSE?\n",
    "3. Which functions correspond to these measures in `scikit-learn`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3746ce9b-b2b4-4841-9421-e215f87b28d5",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16eda68f-eddc-4339-af6e-f0d193d90183",
   "metadata": {},
   "source": [
    "#### $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe11c12-ab01-43a4-9b38-10b2c68a21d7",
   "metadata": {},
   "source": [
    "1. Write down the formula for the $R^2$ measure.\n",
    "2. Look at the formula and try to understand what the $R^2$ measure intuitively measures. **Hint:** Consider the case were we only predict the mean $\\bar{y}$.\n",
    "3. Which functions corresponds to $R^2$ in `scikit-learn`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f600daad-3389-45ec-a8bf-0e5e560a909d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "935da6f7-6feb-4625-b7f5-5dc2123a4943",
   "metadata": {},
   "source": [
    "## Train / Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c47c0d-ff6a-4bd2-888b-5471de9b0b5b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "1. Use `train_test_split` to shuffle and split the given data `(X, y)` into a train and a test dataset with a 80:20 ratio. (**Hint:** you can use the parameters `shuffle` and `test_size`)\n",
    "2. Train the `DecisionTreeClassifier` on the training dataset.\n",
    "3. Calculate the ROC AUC score for the training and the test dataset.\n",
    "4. What do you observe?\n",
    "5. Why should we always have a test set?\n",
    "5. Why should we NEVER fit a model before we define a test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "id": "ef84d2b9-a090-4d07-a4e2-b105620f075c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 1000\n",
    "n_features = 100\n",
    "X = np.random.random((n_samples, n_features))\n",
    "y = np.random.choice([0, 1], p=(0.5, 0.5), size=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "id": "abced26f-a9f9-44c5-89e5-a207c1e9be8c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d563c4-ddb0-403f-b5b8-f23c8632310a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0e859e5-f56e-4bd0-9e32-e0d106515cf5",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc48bfe-cafc-4fcc-a50c-ebf95f1abac9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Consider the following dataset `(X, y)`. We already split it into a train `(X_train, y_train)`, `(X_val, y_val)`, and a test set `(X_test, y_test)`.\n",
    "\n",
    "1. Fit a `DecisionTreeClassifier` on the train dataset.\n",
    "2. Calculate the ROC AUC score on the train, validation, and test dataset. What do you observe?\n",
    "3. How would you apply cross validation and how would it help you?\n",
    "4. Apply cross validation appropriately and report the mean and standard deviation of the ROC AUC scores.\n",
    "5. In addition to the ROC AUC score on the test set, why would you also always report the mean and standard deviation of the cross validations scores?\n",
    "6. Why would you be a bit suspicious of the current AUC SCORE on the test set?\n",
    "7. BONUS: Why are we observing these results based on the data we use? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1685,
   "id": "4c003fc5-811a-42ab-9e4c-a368cfb6b901",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1686,
   "id": "7b550b90-4b9d-4d1b-9b0c-e55005a9e4b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 200 * 6\n",
    "X, y = make_classification(n_samples=n_samples, flip_y=0.01, n_redundant=2, n_informative=2)\n",
    "X[-2*int(n_samples / 6):-int(n_samples / 6),:] = np.random.random((int(n_samples / 6), X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1687,
   "id": "9e64d3d4-6def-45d2-b3c5-985fca436b13",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the test set\n",
    "X_intermediate, X_test, y_intermediate, y_test = train_test_split(X, y, test_size=1/6, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1688,
   "id": "f65da64d-2c4f-41fe-a695-5418e23c1293",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use the remaining data to define the train and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_intermediate, y_intermediate, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1689,
   "id": "f886b012-a472-4796-b811-596e3b341f98",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train\n",
    "X_val, y_val\n",
    "X_test, y_test\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff8304d-9f6e-4e38-addf-5a3e1ab5d76f",
   "metadata": {},
   "source": [
    "## Overfitting / Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f223b72-3e19-44bb-8362-cc2a919e8ec8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "1. Explain the bias / variance trade-off in your own words.\n",
    "2. For the data below, plot `X` against `y_orig` and `X` against `y` (**hint**: `y` is a noisy variant of `y_orig`).\n",
    "3. Split the data into train (80%) and test (20%) sets. \n",
    "4. Fit a `DecisionTreeRegressor` and calculate the mean absolute error for train and test set\n",
    "5. Visualize the predictions for train and test.\n",
    "6. Try different `max_depth`. Can you underfit, fit well, and overfit?\n",
    "7. How does this connect to the bias / variance trade-off?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1692,
   "id": "9a4378b1-8f9b-4a17-aed5-bb0a1d407c55",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be7c14a0-e248-4c2d-a003-c8cf5d343fdd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_steps = 4\n",
    "X = np.arange(50 * n_steps).reshape((-1,1))\n",
    "y_orig = np.repeat(np.arange(4), int(X.shape[0] / n_steps))\n",
    "y = y_orig + (np.random.random(y_orig.size) - 0.5) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f5ab9-a1da-4844-bc1b-9a38e6964cff",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
